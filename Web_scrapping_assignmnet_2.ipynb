{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee07ef8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Obtaining dependency information for selenium from https://files.pythonhosted.org/packages/dc/72/96b5afa16908f9abc7c24b70adfd3a46c9740eb728ddfeab28379e38eaf9/selenium-4.16.0-py3-none-any.whl.metadata\n",
      "  Downloading selenium-4.16.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Obtaining dependency information for trio~=0.17 from https://files.pythonhosted.org/packages/39/46/620fbe56f41fa3ccdda2136d947fb9bacce3d1eb163f057f0262a0ddf5e0/trio-0.23.1-py3-none-any.whl.metadata\n",
      "  Downloading trio-0.23.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Obtaining dependency information for trio-websocket~=0.9 from https://files.pythonhosted.org/packages/48/be/a9ae5f50cad5b6f85bd2574c2c923730098530096e170c1ce7452394d7aa/trio_websocket-0.11.1-py3-none-any.whl.metadata\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Obtaining dependency information for outcome from https://files.pythonhosted.org/packages/55/8b/5ab7257531a5d830fc8000c476e63c935488d74609b50f9384a643ec0a62/outcome-1.3.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading selenium-4.16.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/10.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.7/10.0 MB 18.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 22.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.8/10.0 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.0 MB 21.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.3/10.0 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.0 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.6/10.0 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.8/10.0 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 19.9 MB/s eta 0:00:00\n",
      "Downloading trio-0.23.1-py3-none-any.whl (448 kB)\n",
      "   ---------------------------------------- 0.0/448.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 448.3/448.3 kB 27.4 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.16.0 sniffio-1.3.0 trio-0.23.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "#ANS:1\n",
    "\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e997efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b14066a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf27ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83f64a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_shine_data_with_selenium(job_title, location, num_jobs=10):\n",
    "    # Step 1: Get the webpage\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver_path)\n",
    "    driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "    # Step 2: Enter job title and location\n",
    "    job_title_input = driver.find_element_by_id(\"query_skills\")\n",
    "    job_title_input.clear()\n",
    "    job_title_input.send_keys(job_title)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7072695a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1465606543.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    search_button = driver.find_element_by_id(\"search\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "location_input = driver.find_element_by_id(\"search-keyword\")\n",
    "location_input.clear()\n",
    "location_input.send_keys(location)\n",
    "\n",
    "# Step 3: Click the search button\n",
    "    search_button = driver.find_element_by_id(\"search\")\n",
    "    search_button.click()\n",
    "\n",
    "    # Wait for a moment to allow the page to load\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Step 4: Scrape data for the first 10 jobs\n",
    "    jobs = []\n",
    "    job_elements = driver.find_elements_by_class_name(\"search_listing\")[:num_jobs]\n",
    "    for job_element in job_elements:\n",
    "        job_title = job_element.find_element_by_class_name(\"job_title\").text.strip()\n",
    "        job_location = job_element.find_element_by_class_name(\"job_location\").text.strip()\n",
    "        company_name = job_element.find_element_by_class_name(\"job_title\").get_attribute(\"title\").strip()\n",
    "        experience_required = job_element.find_element_by_class_name(\"exp\").text.strip()\n",
    "\n",
    "        jobs.append({\n",
    "            'Job Title': job_title,\n",
    "            'Job Location': job_location,\n",
    "            'Company Name': company_name,\n",
    "            'Experience Required': experience_required\n",
    "        })\n",
    "\n",
    "    # Step 5: Create a DataFrame\n",
    "    df = pd.DataFrame(jobs)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_title = \"Data Analyst\"\n",
    "    location = \"Bangalore\"\n",
    "    num_jobs = 10\n",
    "\n",
    "    df = scrape_shine_data_with_selenium(job_title, location, num_jobs)\n",
    "\n",
    "    print(\"Scraped Data:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66662497",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WebDriver.__init__() got an unexpected keyword argument 'executable_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBangalore\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m num_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m---> 60\u001b[0m df \u001b[38;5;241m=\u001b[39m scrape_data_scientist_jobs(job_title, location, num_jobs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraped Data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[1;32mIn[32], line 14\u001b[0m, in \u001b[0;36mscrape_data_scientist_jobs\u001b[1;34m(job_title, location, num_jobs)\u001b[0m\n\u001b[0;32m     11\u001b[0m chromedriver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/path/to/chromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update this path with your actual path\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Step 1: Get the webpage\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(executable_path\u001b[38;5;241m=\u001b[39mchromedriver_path)\n\u001b[0;32m     15\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.shine.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 2: Enter job title and location\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: WebDriver.__init__() got an unexpected keyword argument 'executable_path'"
     ]
    }
   ],
   "source": [
    "#ANS:2\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_data_scientist_jobs(job_title, location, num_jobs=10):\n",
    "    # Set the path to your ChromeDriver executable\n",
    "    chromedriver_path = '/path/to/chromedriver'  # Update this path with your actual path\n",
    "\n",
    "    # Step 1: Get the webpage\n",
    "    driver = webdriver.Chrome(executable_path=chromedriver_path)\n",
    "    driver.get(\"https://www.shine.com/\")\n",
    "\n",
    "    # Step 2: Enter job title and location\n",
    "    job_title_input = driver.find_element(By.ID, \"query_skills\")\n",
    "    job_title_input.clear()\n",
    "    job_title_input.send_keys(job_title)\n",
    "\n",
    "    location_input = driver.find_element(By.ID, \"search-keyword\")\n",
    "    location_input.clear()\n",
    "    location_input.send_keys(location)\n",
    "\n",
    "    # Step 3: Click the search button\n",
    "    search_button = driver.find_element(By.ID, \"search\")\n",
    "    search_button.click()\n",
    "\n",
    "    # Wait for a moment to allow the page to load\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Step 4: Scrape data for the first 10 jobs\n",
    "    jobs = []\n",
    "    job_elements = driver.find_elements(By.CLASS_NAME, \"search_listing\")[:num_jobs]\n",
    "    for job_element in job_elements:\n",
    "        job_title = job_element.find_element(By.CLASS_NAME, \"job_title\").text.strip()\n",
    "        job_location = job_element.find_element(By.CLASS_NAME, \"job_location\").text.strip()\n",
    "        company_name = job_element.find_element(By.CLASS_NAME, \"job_title\").get_attribute(\"title\").strip()\n",
    "\n",
    "        jobs.append({\n",
    "            'Job Title': job_title,\n",
    "            'Job Location': job_location,\n",
    "            'Company Name': company_name\n",
    "        })\n",
    "\n",
    "    # Step 5: Create a DataFrame\n",
    "    df = pd.DataFrame(jobs)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    job_title = \"Data Scientist\"\n",
    "    location = \"Bangalore\"\n",
    "    num_jobs = 10\n",
    "\n",
    "    df = scrape_data_scientist_jobs(job_title, location, num_jobs)\n",
    "\n",
    "    print(\"Scraped Data:\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85233067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: selenium in c:\\users\\shivam\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\shivam\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#Ans:3) pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install selenium\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893878cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9280e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the web page\n",
    "url = \"https://www.shine.com/\"\n",
    "driver = webdriver.Chrome()  # Use the appropriate webdriver for your browser (e.g., ChromeDriver)\n",
    "driver.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1783cf35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"qryIdTxt\"]\"}\n  (Session info: chrome=120.0.6099.71); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7BC5B4D02+56194]\n\t(No symbol) [0x00007FF7BC5204B2]\n\t(No symbol) [0x00007FF7BC3C76AA]\n\t(No symbol) [0x00007FF7BC4116D0]\n\t(No symbol) [0x00007FF7BC4117EC]\n\t(No symbol) [0x00007FF7BC454D77]\n\t(No symbol) [0x00007FF7BC435EBF]\n\t(No symbol) [0x00007FF7BC452786]\n\t(No symbol) [0x00007FF7BC435C23]\n\t(No symbol) [0x00007FF7BC404A45]\n\t(No symbol) [0x00007FF7BC405AD4]\n\tGetHandleVerifier [0x00007FF7BC92D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7BC986197+4059159]\n\tGetHandleVerifier [0x00007FF7BC97DF63+4025827]\n\tGetHandleVerifier [0x00007FF7BC64F029+687785]\n\t(No symbol) [0x00007FF7BC52B508]\n\t(No symbol) [0x00007FF7BC527564]\n\t(No symbol) [0x00007FF7BC5276E9]\n\t(No symbol) [0x00007FF7BC518094]\n\tBaseThreadInitThunk [0x00007FFA2C587344+20]\n\tRtlUserThreadStart [0x00007FFA2C9E26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: Enter \"Data Scientist\" in the search field and click the search button\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_box \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqryIdTxt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Scientist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m search_box\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mRETURN)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:742\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    739\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    740\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"qryIdTxt\"]\"}\n  (Session info: chrome=120.0.6099.71); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7BC5B4D02+56194]\n\t(No symbol) [0x00007FF7BC5204B2]\n\t(No symbol) [0x00007FF7BC3C76AA]\n\t(No symbol) [0x00007FF7BC4116D0]\n\t(No symbol) [0x00007FF7BC4117EC]\n\t(No symbol) [0x00007FF7BC454D77]\n\t(No symbol) [0x00007FF7BC435EBF]\n\t(No symbol) [0x00007FF7BC452786]\n\t(No symbol) [0x00007FF7BC435C23]\n\t(No symbol) [0x00007FF7BC404A45]\n\t(No symbol) [0x00007FF7BC405AD4]\n\tGetHandleVerifier [0x00007FF7BC92D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7BC986197+4059159]\n\tGetHandleVerifier [0x00007FF7BC97DF63+4025827]\n\tGetHandleVerifier [0x00007FF7BC64F029+687785]\n\t(No symbol) [0x00007FF7BC52B508]\n\t(No symbol) [0x00007FF7BC527564]\n\t(No symbol) [0x00007FF7BC5276E9]\n\t(No symbol) [0x00007FF7BC518094]\n\tBaseThreadInitThunk [0x00007FFA2C587344+20]\n\tRtlUserThreadStart [0x00007FFA2C9E26B1+33]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Enter \"Data Scientist\" in the search field and click the search button\n",
    "search_box = driver.find_element(\"id\", \"qryIdTxt\")\n",
    "search_box.send_keys(\"Data Scientist\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANS:4)\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "# Step 1: Go to Flipkart webpage\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver = webdriver.Chrome()  # Use the appropriate webdriver for your browser (e.g., ChromeDriver)\n",
    "driver.get(url)\n",
    "\n",
    "# Step 2: Enter \"sunglasses\" in the search field and click the search icon\n",
    "search_box = driver.find_element(\"name\", \"q\")\n",
    "search_box.send_keys(\"sunglasses\")\n",
    "search_box.submit()\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 3-6: Scrape data from each page until 100 sunglasses are scraped\n",
    "sunglasses_data = []\n",
    "\n",
    "while len(sunglasses_data) < 100:\n",
    "    # Scrape data from the current page\n",
    "    page_html = driver.page_source\n",
    "    page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "    \n",
    "    sunglasses_listings = page_soup.find_all(\"div\", class_=\"_1AtVbE\")\n",
    "    \n",
    "    for listing in sunglasses_listings:\n",
    "        brand = listing.select_one(\"div._2WkVRV\").text.strip()\n",
    "        product_description = listing.select_one(\"aIR6Io\").text.strip()\n",
    "        price = listing.select_one(\"._30jeq3\").text.strip()\n",
    "        \n",
    "        sunglasses_data.append({\n",
    "            \"Brand\": brand,\n",
    "            \"Product Description\": product_description,\n",
    "            \"Price\": price\n",
    "        })\n",
    "\n",
    "    # Check if we have enough data (100 sunglasses)\n",
    "    if len(sunglasses_data) >= 100:\n",
    "        break\n",
    "\n",
    "    # Move to the next page\n",
    "    next_button = driver.find_element_by_css_selector(\"a._1LKTO3\")\n",
    "    if next_button:\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Step 7: Create a dataframe of the scraped data\n",
    "df_sunglasses = pd.DataFrame(sunglasses_data)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df_sunglasses)\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d1f0b16",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     rating \u001b[38;5;241m=\u001b[39m review\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv._3LWZlK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     25\u001b[0m     review_summary \u001b[38;5;241m=\u001b[39m review\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp._2-N8zT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 26\u001b[0m     full_review \u001b[38;5;241m=\u001b[39m review\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv.qwjRop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     28\u001b[0m     reviews_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m\"\u001b[39m: rating,\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m: review_summary,\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull Review\u001b[39m\u001b[38;5;124m\"\u001b[39m: full_review\n\u001b[0;32m     32\u001b[0m     })\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Check if we have enough data (100 reviews)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#ANS:5)\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "# Step 1: Go to the Flipkart review page for iPhone 11\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\"\n",
    "driver = webdriver.Chrome()  # Use the appropriate webdriver for your browser (e.g., ChromeDriver)\n",
    "driver.get(url)\n",
    "\n",
    "# Step 2-5: Scrape data for the first 100 reviews\n",
    "reviews_data = []\n",
    "\n",
    "while len(reviews_data) < 100:\n",
    "    # Scrape data from the current page\n",
    "    page_html = driver.page_source\n",
    "    page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "    \n",
    "    reviews = page_soup.find_all(\"div\", class_=\"_27M-vq\")\n",
    "    \n",
    "    for review in reviews:\n",
    "        rating = review.select_one(\"div._3LWZlK\").text.strip()\n",
    "        review_summary = review.select_one(\"p._2-N8zT\").text.strip()\n",
    "        full_review = review.select_one(\"div.qwjRop\").text.strip()\n",
    "        \n",
    "        reviews_data.append({\n",
    "            \"Rating\": rating,\n",
    "            \"Review Summary\": review_summary,\n",
    "            \"Full Review\": full_review\n",
    "        })\n",
    "\n",
    "    # Check if we have enough data (100 reviews)\n",
    "    if len(reviews_data) >= 100:\n",
    "        break\n",
    "\n",
    "    # Move to the next page\n",
    "    next_button = driver.find_element_by_css_selector(\"a._1LKTO3\")\n",
    "    if next_button:\n",
    "        next_button.click()\n",
    "        time.sleep(2)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Step 6: Create a dataframe of the scraped data\n",
    "df_reviews = pd.DataFrame(reviews_data)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df_reviews)\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e293fc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (286818039.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 37\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"Brand\"\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "#ANS:7\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "# Step 1: Go to the Flipkart webpage and search for \"sneakers\"\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver = webdriver.Chrome()  # Use the appropriate webdriver for your browser (e.g., ChromeDriver)\n",
    "driver.get(url)\n",
    "\n",
    "# Enter \"sneakers\" in the search field and click the search icon\n",
    "search_box = driver.find_element(\"name\", \"q\")\n",
    "search_box.send_keys(\"sneakers\")\n",
    "search_box.submit()\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 2-5: Scrape data for the first 100 sneakers\n",
    "sneakers_data = []\n",
    "\n",
    "while len(sneakers_data) < 100:\n",
    "    # Scrape data from the current page\n",
    "    page_html = driver.page_source\n",
    "    page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "    \n",
    "    sneakers_listings = page_soup.find_all(\"div\", class_=\"_1AtVbE\")\n",
    "    \n",
    "    for listing in sneakers_listings:\n",
    "        brand = listing.select_one(\"div._2WkVRV\").text.strip()\n",
    "        product_description = listing.select_one(\"aIR6Io\").text.strip()\n",
    "        price = listing.select_one(\"._30jeq3\").text.strip()\n",
    "        \n",
    "        sneakers_data.append({\n",
    "            \"Brand\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a472698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\shivam\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\shivam\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#ANS:9)\n",
    "\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbb78fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"link text\",\"selector\":\"List of all Prime Ministers of India\"}\n  (Session info: chrome=120.0.6099.71); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7BC5B4D02+56194]\n\t(No symbol) [0x00007FF7BC5204B2]\n\t(No symbol) [0x00007FF7BC3C76AA]\n\t(No symbol) [0x00007FF7BC4116D0]\n\t(No symbol) [0x00007FF7BC4117EC]\n\t(No symbol) [0x00007FF7BC454D77]\n\t(No symbol) [0x00007FF7BC435EBF]\n\t(No symbol) [0x00007FF7BC452786]\n\t(No symbol) [0x00007FF7BC435C23]\n\t(No symbol) [0x00007FF7BC404A45]\n\t(No symbol) [0x00007FF7BC405AD4]\n\tGetHandleVerifier [0x00007FF7BC92D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7BC986197+4059159]\n\tGetHandleVerifier [0x00007FF7BC97DF63+4025827]\n\tGetHandleVerifier [0x00007FF7BC64F029+687785]\n\t(No symbol) [0x00007FF7BC52B508]\n\t(No symbol) [0x00007FF7BC527564]\n\t(No symbol) [0x00007FF7BC5276E9]\n\t(No symbol) [0x00007FF7BC518094]\n\tBaseThreadInitThunk [0x00007FFA2C587344+20]\n\tRtlUserThreadStart [0x00007FFA2C9E26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 3: Click on \"List of all Prime Ministers of India\"\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m prime_ministers_link \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mLINK_TEXT, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList of all Prime Ministers of India\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m prime_ministers_link\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Wait for the page to load\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:742\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    739\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    740\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mFIND_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"link text\",\"selector\":\"List of all Prime Ministers of India\"}\n  (Session info: chrome=120.0.6099.71); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7BC5B4D02+56194]\n\t(No symbol) [0x00007FF7BC5204B2]\n\t(No symbol) [0x00007FF7BC3C76AA]\n\t(No symbol) [0x00007FF7BC4116D0]\n\t(No symbol) [0x00007FF7BC4117EC]\n\t(No symbol) [0x00007FF7BC454D77]\n\t(No symbol) [0x00007FF7BC435EBF]\n\t(No symbol) [0x00007FF7BC452786]\n\t(No symbol) [0x00007FF7BC435C23]\n\t(No symbol) [0x00007FF7BC404A45]\n\t(No symbol) [0x00007FF7BC405AD4]\n\tGetHandleVerifier [0x00007FF7BC92D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7BC986197+4059159]\n\tGetHandleVerifier [0x00007FF7BC97DF63+4025827]\n\tGetHandleVerifier [0x00007FF7BC64F029+687785]\n\t(No symbol) [0x00007FF7BC52B508]\n\t(No symbol) [0x00007FF7BC527564]\n\t(No symbol) [0x00007FF7BC5276E9]\n\t(No symbol) [0x00007FF7BC518094]\n\tBaseThreadInitThunk [0x00007FFA2C587344+20]\n\tRtlUserThreadStart [0x00007FFA2C9E26B1+33]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Step 1: Get the webpage\n",
    "url = \"https://www.jagranjosh.com/\"\n",
    "driver = webdriver.Chrome()  # Use the appropriate webdriver for your browser (e.g., ChromeDriver)\n",
    "driver.get(url)\n",
    "\n",
    "# Step 2: Click on \"GK\" option\n",
    "gk_option = driver.find_element(By.LINK_TEXT, \"GK\")\n",
    "gk_option.click()\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 3: Click on \"List of all Prime Ministers of India\"\n",
    "prime_ministers_link = driver.find_element(By.LINK_TEXT, \"List of all Prime Ministers of India\")\n",
    "prime_ministers_link.click()\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 4: Scrape the data for Name, Born-Dead, Term of office, Remarks\n",
    "prime_ministers_data = []\n",
    "\n",
    "table_rows = driver.find_elements(By.CSS_SELECTOR, \".tab-board tr\")[1:]  # Skipping the header row\n",
    "\n",
    "for row in table_rows:\n",
    "    columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    name = columns[0].text.strip()\n",
    "    born_dead = columns[1].text.strip()\n",
    "    term_of_office = columns[2].text.strip()\n",
    "    remarks = columns[3].text.strip()\n",
    "\n",
    "    prime_ministers_data.append({\n",
    "        \"Name\": name,\n",
    "        \"Born-Dead\": born_dead,\n",
    "        \"Term of Office\": term_of_office,\n",
    "        \"Remarks\": remarks\n",
    "    })\n",
    "\n",
    "# Step 5: Create a dataframe of the scraped data\n",
    "df_prime_ministers = pd.DataFrame(prime_ministers_data)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df_prime_ministers)\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "008c0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\shivam\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\shivam\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#ANS: 10) \n",
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6fc53a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=120.0.6099.71)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7BC5B4D02+56194]\n\t(No symbol) [0x00007FF7BC5204B2]\n\t(No symbol) [0x00007FF7BC3C76AA]\n\t(No symbol) [0x00007FF7BC3A0AFD]\n\t(No symbol) [0x00007FF7BC43C9AB]\n\t(No symbol) [0x00007FF7BC45201F]\n\t(No symbol) [0x00007FF7BC435C23]\n\t(No symbol) [0x00007FF7BC404A45]\n\t(No symbol) [0x00007FF7BC405AD4]\n\tGetHandleVerifier [0x00007FF7BC92D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7BC986197+4059159]\n\tGetHandleVerifier [0x00007FF7BC97DF63+4025827]\n\tGetHandleVerifier [0x00007FF7BC64F029+687785]\n\t(No symbol) [0x00007FF7BC52B508]\n\t(No symbol) [0x00007FF7BC527564]\n\t(No symbol) [0x00007FF7BC5276E9]\n\t(No symbol) [0x00007FF7BC518094]\n\tBaseThreadInitThunk [0x00007FFA2C587344+20]\n\tRtlUserThreadStart [0x00007FFA2C9E26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m search_bar \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m50 most expensive cars\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m search_bar\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mRETURN)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Wait for the search results to load\u001b[39;00m\n\u001b[0;32m     17\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(\n\u001b[0;32m    232\u001b[0m     Command\u001b[38;5;241m.\u001b[39mSEND_KEYS_TO_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(keys_to_typing(value)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: keys_to_typing(value)}\n\u001b[0;32m    233\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=120.0.6099.71)\nStacktrace:\n\tGetHandleVerifier [0x00007FF7BC5B4D02+56194]\n\t(No symbol) [0x00007FF7BC5204B2]\n\t(No symbol) [0x00007FF7BC3C76AA]\n\t(No symbol) [0x00007FF7BC3A0AFD]\n\t(No symbol) [0x00007FF7BC43C9AB]\n\t(No symbol) [0x00007FF7BC45201F]\n\t(No symbol) [0x00007FF7BC435C23]\n\t(No symbol) [0x00007FF7BC404A45]\n\t(No symbol) [0x00007FF7BC405AD4]\n\tGetHandleVerifier [0x00007FF7BC92D5BB+3695675]\n\tGetHandleVerifier [0x00007FF7BC986197+4059159]\n\tGetHandleVerifier [0x00007FF7BC97DF63+4025827]\n\tGetHandleVerifier [0x00007FF7BC64F029+687785]\n\t(No symbol) [0x00007FF7BC52B508]\n\t(No symbol) [0x00007FF7BC527564]\n\t(No symbol) [0x00007FF7BC5276E9]\n\t(No symbol) [0x00007FF7BC518094]\n\tBaseThreadInitThunk [0x00007FFA2C587344+20]\n\tRtlUserThreadStart [0x00007FFA2C9E26B1+33]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Step 1: Get the webpage\n",
    "url = \"https://www.motor1.com/\"\n",
    "driver = webdriver.Chrome()  # Use the appropriate webdriver for your browser (e.g., ChromeDriver)\n",
    "driver.get(url)\n",
    "\n",
    "# Step 2: Type in the search bar '50 most expensive cars'\n",
    "search_bar = driver.find_element(\"name\", \"q\")\n",
    "search_bar.send_keys(\"50 most expensive cars\")\n",
    "search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for the search results to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 3: Click on '50 most expensive cars in the world..'\n",
    "result_link = driver.find_element_by_partial_link_text(\"50 Most Expensive Cars In The World\")\n",
    "result_link.click()\n",
    "\n",
    "# Wait for the result page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Step 4: Scrap the data for Car name and Price\n",
    "cars_data = []\n",
    "\n",
    "car_name_elements = driver.find_elements_by_class_name(\"name\")\n",
    "car_price_elements = driver.find_elements_by_class_name(\"price\")\n",
    "\n",
    "for name, price in zip(car_name_elements, car_price_elements):\n",
    "    car_name = name.text.strip()\n",
    "    car_price = price.text.strip()\n",
    "\n",
    "    cars_data.append({\n",
    "        \"Car Name\": car_name,\n",
    "        \"Price\": car_price\n",
    "    })\n",
    "\n",
    "# Step 5: Create a dataframe of the scraped data\n",
    "df_cars = pd.DataFrame(cars_data)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df_cars)\n",
    "\n",
    "# Close the webdriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07291a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ec2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
